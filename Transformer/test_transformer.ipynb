{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "random.seed(43)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find device\n",
    "if torch.cuda.is_available(): # NVIDIA\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available(): # apple silicon\n",
    "    device = torch.device('mps') \n",
    "else:\n",
    "    device = torch.device('cpu') # fallback\n",
    "device = device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cpus = os.cpu_count()\n",
    "print(num_cpus, 'CPUs available')\n",
    "num_cpus = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataai=\"../data/WISDM_ar_v1.1/\"\n",
    "datapath =  dataai\n",
    "col_names = ['user', 'activity', 'timestamp', 'x-accel', 'y-accel', 'z-accel']\n",
    "\n",
    "df = pd.read_csv(datapath+\"WISDM_ar_v1.1_raw.txt\",\n",
    "                  header=None, names=col_names, delimiter=',', comment=';',\n",
    "                    on_bad_lines='skip') #skip/warn bad lines\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_usrs = df['user'].unique()\n",
    "print(num_usrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = df.activity.unique()\n",
    "num_channels =3 # x-accel, y-accel, z-accel\n",
    "num_classes = len(class_labels)\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_to_label = {activity: i for i, activity in enumerate(df['activity'].unique())}\n",
    "print(activity_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by users and activity\n",
    "grouped = df.groupby(['user', 'activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine X, Y, Z into a single time-series for each group\n",
    "time_series = []\n",
    "labels = []\n",
    "activity_to_label = {activity: i for i, activity in enumerate(df['activity'].unique())}\n",
    "\n",
    "for (user, activity), group in grouped:\n",
    "    # Stack X, Y, Z into a single array of shape (timesteps, 3)\n",
    "    series = np.column_stack((group['x-accel'], group['y-accel'], group['z-accel']))\n",
    "    time_series.append(series)\n",
    "    labels.append(activity_to_label[activity])\n",
    "\n",
    "print(time_series[0].shape)\n",
    "print(len(labels), np.unique(labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad/truncate to a fixed length\n",
    "max_length = 4*1000  # Choose a fixed length\n",
    "padded_series = nn.utils.rnn.pad_sequence([torch.tensor(series, dtype=torch.float32) for series in time_series],\n",
    "                             batch_first=True, padding_value=0)\n",
    "print(padded_series.shape)\n",
    "padded_series = padded_series[:, :max_length, :]  # Truncate to max_length if necessary\n",
    "\n",
    "\n",
    "# Normalize (not needed here, but keep it for plotting)\n",
    "# padded_series = nn.functional.normalize(padded_series, dim=2, p=2)\n",
    "print(padded_series.shape, len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add segments\n",
    "segment_duration = 100\n",
    "# Calculate the number of segments per sample\n",
    "num_segments = padded_series.shape[1] // segment_duration\n",
    "print(\" shape of all segmented data\", padded_series.shape[0]*num_segments, segment_duration, padded_series.shape[2])\n",
    "reshaped_data = padded_series.reshape(padded_series.shape[0], num_segments, segment_duration, padded_series.shape[2])\n",
    "\n",
    "valid_segments = []\n",
    "valid_labels = []\n",
    "\n",
    "# Iterate over each sample and its segments to remove segments with all zeros x,y,z\n",
    "for sample_idx in range(reshaped_data.shape[0]):\n",
    "    for segment_idx in range(reshaped_data.shape[1]):\n",
    "        segment = reshaped_data[sample_idx, segment_idx]\n",
    "        if not (torch.all(segment[:, 0]==0) and torch.all(segment[:, 1]==0) and torch.all(segment[:, 2]==0) ):\n",
    "            valid_segments.append(segment)\n",
    "            valid_labels.append(labels[sample_idx])\n",
    "\n",
    "padded_series = torch.stack(valid_segments)\n",
    "labels = torch.tensor(valid_labels)\n",
    "max_length = segment_duration\n",
    "print(\" shape of segmented data with nonzero features\",padded_series.shape, labels.shape)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynumpy = np.array(labels)\n",
    "class_weights=class_weight.compute_class_weight(class_weight=\"balanced\", classes=np.unique(ynumpy), y=ynumpy) \n",
    "class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "print(np.unique(ynumpy),class_weights)\n",
    "print(class_weights.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized series\n",
    "num= 178\n",
    "fig, ax = plt.subplots(5, 1, figsize=(6, 8))\n",
    "i=0\n",
    "for num in [1, 50, 100, 150, 170]:\n",
    "    print(padded_series[num][99])\n",
    "    ax[i].plot(padded_series[num][:, 0],\n",
    "            label=f'X:{list(activity_to_label.keys())[list(activity_to_label.values()).index(labels[num])]}')\n",
    "    ax[i].plot(padded_series[num][:, 1],\n",
    "            label=f'Y:{list(activity_to_label.keys())[list(activity_to_label.values()).index(labels[num])]}')\n",
    "    ax[i].plot(padded_series[num][:, 2],\n",
    "            label=f'Z:{list(activity_to_label.keys())[list(activity_to_label.values()).index(labels[num])]}')\n",
    "    ax[i].legend()\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transformer import run_training_testing_transformer\n",
    "\n",
    "# print(padded_series.shape)\n",
    "run_training_testing_transformer.run_transformer_training(padded_series, labels, class_labels, \n",
    "                                                  device, num_channels, num_classes,test_size=0.3,\n",
    "                                                  val_size=0.1, batch_size=8, num_cpus=1,lr=0.001, \n",
    "                                                  num_epochs=10,  patience=5, modeltype = \"trans1\",\n",
    "                                                  max_length_series=segment_duration, embed_size = 16, nhead = 8,\n",
    "                                                  dim_feedforward = 32, num_encoderlayers=4, dropout = 0.0, conv1d_emb = True,\n",
    "                                                  conv1d_kernel_size =7, size_linear_layers = 16,\n",
    "                                                  opt=\"adamW\", verbose=False, \n",
    "                                                  pathsave=\"./Figs/\", weights=None, norm_type=\"per-channel\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
